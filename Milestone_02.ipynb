{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone Two\n",
    "\n",
    "**Data Preparation and Model Exploration**\n",
    "**Due:** Midnight on November 16th with usual 2-hour grace period — **worth 100 points**\n",
    "\n",
    "**Note: No late assignments accepted, we need the time to grade them!**\n",
    "\n",
    "In Milestone 1, your team selected a dataset (Food-101 or HuffPost), analyzed its structure, and identified key challenges and evaluation metrics.\n",
    "In this milestone, you will carry out those plans: prepare the data, train three models of increasing sophistication, and evaluate their results using Keras and TensorFlow.\n",
    "You will finish with a comparative discussion of model performance and trade-offs.\n",
    "\n",
    "\n",
    "### Submission Guidelines\n",
    "\n",
    "* Submit one Jupyter notebook per team through the team leader’s Gradescope account. **Include all team members names at the top of the notebook.** \n",
    "* Include all code, plots, and answers inline below.\n",
    "* Ensure reproducibility by setting random seeds and listing all hyperparameters.\n",
    "* Document any AI tools used, as required by the CDS policy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tfmetal/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading huffpost dataset\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# Useful Imports\n",
    "# ============================================\n",
    "\n",
    "# --- Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "# --- Core Data / Numerics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns              # optional\n",
    "import matplotlib.ticker as mticker  # optional (for formatted axes)\n",
    "\n",
    "# --- NLP / Tokenization\n",
    "import spacy                         # used for text preprocessing (HuffPost)\n",
    "\n",
    "# --- Progress Tracking\n",
    "from tqdm import tqdm                # optional (nice for loops)\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# --- TensorFlow / Keras (Deep Learning)\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, Input, callbacks, regularizers, initializers\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecay, ExponentialDecay\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.layers import (\n",
    "    Dense, Dropout, Flatten, MaxPooling2D, Conv2D,\n",
    "    SeparableConv2D, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization\n",
    ")\n",
    "\n",
    "# hugging face\n",
    "# --- Hugging Face Datasets\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from datasets.features import ClassLabel\n",
    "\n",
    "# --- (Optional) Classical ML Baseline Tools\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# ============================================\n",
    "# Global Configuration & Small Utilities\n",
    "# ============================================\n",
    "\n",
    "# Reproducibility\n",
    "random_seed = 42\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "tf.keras.utils.set_random_seed(random_seed)   # sets Python, NumPy, and TensorFlow seeds\n",
    "\n",
    "# Utility: format seconds as HH:MM:SS\n",
    "\n",
    "\"\"\"\n",
    "Example usage to time your code:\n",
    "\n",
    "start_time = time.time()\n",
    "# ... your code here ...\n",
    "print(\"Execution Time:\", format_hms(time.time() - start_time))\n",
    "\"\"\"\n",
    "\n",
    "def format_hms(seconds: float) -> str:\n",
    "    \"\"\"Convert seconds to HH:MM:SS format.\"\"\"\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n",
    "# load dataset\n",
    "from datasets import load_from_disk\n",
    "print(\"loading huffpost dataset\")\n",
    "huff_all = load_from_disk(\"huffpost_splits\")  # reload when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 – Data Preparation and Splits (20 pts)\n",
    "\n",
    "### Goals\n",
    "\n",
    "Implement the **data preparation and preprocessing steps** that you proposed in **Milestone 1**. You’ll clean, normalize, and split your data so that it’s ready for modeling and reproducible fine-tuning.\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Load your chosen dataset**\n",
    "\n",
    "   * Use `datasets.load_dataset()` from **Hugging Face** to load **Food-101** or **HuffPost**.\n",
    "   * Display basic information (e.g., number of samples, feature names, example entries).\n",
    "\n",
    "2. **Apply cleaning and normalization**\n",
    "\n",
    "   * **Images:**\n",
    "\n",
    "     * Ensure all images are in RGB format.\n",
    "     * Resize or crop to a consistent shape (e.g., `224 × 224`).\n",
    "     * Drop or fix any corrupted files.\n",
    "   * **Text:**\n",
    "\n",
    "     * Concatenate headline + summary (for HuffPost).\n",
    "     * Strip whitespace, convert to lowercase if appropriate, and remove empty samples.\n",
    "     * Optionally remove duplicates or extremely short entries.\n",
    "\n",
    "3. **Standardize or tokenize the inputs**\n",
    "\n",
    "   * **Images:**\n",
    "\n",
    "     * Normalize pixel values (e.g., divide by 255.0).\n",
    "     * Define a minimal augmentation pipeline (e.g., random flip, crop, or rotation).\n",
    "   * **Text:**\n",
    "\n",
    "     * Create a tokenizer or `TextVectorization` layer.\n",
    "     * Set a target `max_length` based on your analysis from Milestone 1 (e.g., 95th percentile).\n",
    "     * Apply padding/truncation and build tensors for input + labels.\n",
    "\n",
    "4. **Handle dataset-specific challenges**\n",
    "\n",
    "   * If you identified **class imbalance**, compute label counts and, if needed, create a dictionary of `class_weights`.\n",
    "   * If you noted **length or size variance**, verify that your truncation or resizing works as intended.\n",
    "   * If you planned **noise filtering**, include the cleaning step and briefly explain your criteria (e.g., remove items with missing text or unreadable images).\n",
    "\n",
    "5. **Create reproducible splits**\n",
    "\n",
    "   * Split your cleaned dataset into **train**, **validation**, and **test** subsets (e.g., 80 / 10 / 10).\n",
    "   * Use a fixed random seed for reproducibility (`random_seed = 42`).\n",
    "   * Use **stratified splits**  (e.g., with `train_test_split` and `stratify = labels`).\n",
    "   * Display the size of each subset.\n",
    "\n",
    "6. **Document your pipeline**\n",
    "\n",
    "   * Summarize your preprocessing steps clearly in Markdown or code comments.\n",
    "   * Save or display a few representative examples after preprocessing to confirm the transformations are correct.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset and run Emma data cleaning/tokenization scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['category', 'headline', 'authors', 'link', 'short_description', 'date', 'text']\n",
      "{'category': 'CRIME', 'headline': 'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV', 'authors': 'Melissa Jeltsen', 'link': 'https://www.huffingtonpost.com/entry/texas-amanda-painter-mass-shooting_us_5b081ab4e4b0802d69caad89', 'short_description': 'She left her husband. He killed their children. Just another day in America.', 'date': datetime.datetime(2018, 5, 26, 0, 0), 'text': 'There Were 2 Mass Shootings In Texas Last Week, But Only 1 On TV [SEP] She left her husband. He killed their children. Just another day in America.'}\n",
      "\n",
      "Class weights examples:\n",
      "{'ARTS & CULTURE': 3.588648290437555, 'BLACK VOICES': 1.1972739929848044, 'BUSINESS': 0.9127372779825165, 'COLLEGE': 4.733627858627859, 'COMEDY': 1.048658069378441}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:   0%|          | 0/140255 [00:00<?, ? examples/s]TensorFlow and JAX classes are deprecated and will be removed in Transformers v5. We recommend migrating to PyTorch classes or pinning your version of Transformers.\n",
      "2025-11-03 20:51:32.218569: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Max\n",
      "2025-11-03 20:51:32.218634: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 36.00 GB\n",
      "2025-11-03 20:51:32.218653: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 14.04 GB\n",
      "2025-11-03 20:51:32.218675: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2025-11-03 20:51:32.218699: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "Map: 100%|██████████| 140255/140255 [00:05<00:00, 25035.89 examples/s]\n",
      "Map: 100%|██████████| 30055/30055 [00:01<00:00, 26086.64 examples/s]\n",
      "Map: 100%|██████████| 30055/30055 [00:01<00:00, 26305.31 examples/s]\n",
      "Map: 100%|██████████| 140255/140255 [00:07<00:00, 19017.86 examples/s]\n",
      "Map: 100%|██████████| 30055/30055 [00:01<00:00, 18209.82 examples/s]\n",
      "Map: 100%|██████████| 30055/30055 [00:01<00:00, 18261.80 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Your code here; add as many cells as you need but make it clear what the structure is. \n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments\n",
    ")\n",
    "\n",
    "# combine headline & short_description into 1 text field\n",
    "def combine_fields(prob2):\n",
    "  headline = prob2.get('headline', '') or \"\"\n",
    "  short_desc = prob2.get('short_description', '[NO_DESC]') or \"[NO_DESC]\"\n",
    "  prob2['text'] = f\"{headline} [SEP] {short_desc}\"\n",
    "  return prob2\n",
    "\n",
    "huff_all = huff_all.map(combine_fields)\n",
    "print(huff_all.column_names)\n",
    "print(huff_all[0])\n",
    "\n",
    "# write to pandas\n",
    "df_prob2 = huff_all.to_pandas()\n",
    "\n",
    "# Solution 1: Merge Duplicate/Overlapping Categories\n",
    "merge_map = {\n",
    "    'WORLDPOST': 'WORLD NEWS',\n",
    "    'ARTS': 'ARTS & CULTURE',\n",
    "    'ARTS & CULTURE': 'CULTURE & ARTS',\n",
    "    'STYLE': 'STYLE & BEAUTY',\n",
    "    'PARENTS': 'PARENTING'\n",
    "    }\n",
    "df_prob2['category'] = df_prob2['category'].replace(merge_map)\n",
    "\n",
    "# Solution 2: Handle Missing short_description\n",
    "df_prob2['short_description'] = df_prob2['short_description'].replace('','[NO_DESC]').fillna('[NO_DESC]')\n",
    "\n",
    "# Solution 3: Combine headline and short_description into a single field to avoid short text length\n",
    "df_prob2['headline'] = df_prob2['headline'].fillna('')\n",
    "df_prob2['text'] = df_prob2['headline'] + \" [SEP] \" + df_prob2['short_description']\n",
    "\n",
    "# Solution 4: Deduplicating\n",
    "df_prob2 = df_prob2.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Solution 5: Stratified Split with train/val/test/split\n",
    "train_df, temp_df = train_test_split(\n",
    "    df_prob2,\n",
    "    test_size=0.30,\n",
    "    stratify=df_prob2['category'],\n",
    "    random_state=42\n",
    ")\n",
    "val_df, test_df = train_test_split(\n",
    "    temp_df,\n",
    "    test_size=0.50,  # Split temp equally into val/test (15% each of total)\n",
    "    stratify=temp_df['category'],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# convert splits back to Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(train_df[['text', 'category']], preserve_index=False)\n",
    "val_ds   = Dataset.from_pandas(val_df[['text', 'category']], preserve_index=False)\n",
    "test_ds  = Dataset.from_pandas(test_df[['text', 'category']], preserve_index=False)\n",
    "\n",
    "\n",
    "# Solution 6: Compute/Apply Class Weights to handle Imbalance\n",
    "categories = np.unique(df_prob2['category'])\n",
    "weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=categories,\n",
    "    y=df_prob2['category']\n",
    ")\n",
    "\n",
    "print('\\nClass weights examples:')\n",
    "print(dict(zip(categories[:5], weights[:5])))\n",
    "\n",
    "# Solution 7: Tokenization with DistilBERT & max_length=128\n",
    "model_name = 'distilbert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def tokenize_fn(batch):\n",
    "  return tokenizer(\n",
    "      batch['text'],\n",
    "      padding='max_length',\n",
    "      truncation=True,\n",
    "      max_length=128, \n",
    "      return_tensors='tf'\n",
    "  )\n",
    "train_ds = train_ds.map(tokenize_fn, batched=True)\n",
    "val_ds   = val_ds.map(tokenize_fn, batched=True)\n",
    "test_ds  = test_ds.map(tokenize_fn, batched=True)\n",
    "\n",
    "\n",
    "# Solution 8: Label Encode category column into integers\n",
    "le = LabelEncoder()\n",
    "all_labels = list(train_ds['category']) + list(val_ds['category']) + list(test_ds['category'])\n",
    "le.fit(all_labels)\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "def encode_labels(batch):\n",
    "    batch['labels'] = le.transform([batch['category']])[0]\n",
    "    return batch\n",
    "\n",
    "train_ds = train_ds.map(encode_labels)\n",
    "val_ds   = val_ds.map(encode_labels)\n",
    "test_ds  = test_ds.map(encode_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities - load and save datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 140255/140255 [00:00<00:00, 1729744.03 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 30055/30055 [00:00<00:00, 1974033.52 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 30055/30055 [00:00<00:00, 2165827.21 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label encoder saved to label_encoder.pkl\n",
      "Class weights saved to class_weights.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# save datasets to disk for future reload\n",
    "from datasets import DatasetDict\n",
    "import pickle\n",
    "\n",
    "# Create a DatasetDict\n",
    "processed_datasets = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': val_ds,\n",
    "    'test': test_ds\n",
    "})\n",
    "\n",
    "# save to disk\n",
    "processed_datasets.save_to_disk(\"huffpost_processed_milestone2\")\n",
    "\n",
    "# save the label encoder\n",
    "import pickle\n",
    "with open('label_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(le, f)\n",
    "print(\"Label encoder saved to label_encoder.pkl\")\n",
    "\n",
    "# save class weights as well\n",
    "class_weights = weights \n",
    "np.save('class_weights.npy', class_weights)\n",
    "print(\"Class weights saved to class_weights.npy\")\n",
    "\n",
    "\n",
    "# For quick reload! \n",
    "#import pickle\n",
    "\n",
    "#processed_datasets = load_from_disk(\"huffpost_processed_milestone2\")\n",
    "#train_ds = processed_datasets['train']\n",
    "#val_ds = processed_datasets['validation']\n",
    "#test_ds = processed_datasets['test']\n",
    "\n",
    "#with open('label_encoder.pkl', 'rb') as f:\n",
    "#    le = pickle.load(f)\n",
    "\n",
    "# Load weights\n",
    "#class_weights = np.load('class_weights.npy')\n",
    "\n",
    "# Use as TF tensor when needed\n",
    "#class_weights_tf = tf.constant(class_weights, dtype=tf.float32)\n",
    "#num_labels = len(le.classes_)\n",
    "\n",
    "#print(f\"Loaded: Train={len(train_ds)}, Val={len(val_ds)}, Test={len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "For each question, answer thoroughly but concisely, in a short paragraph, longer or shorter as needed. Code for exploring the concepts should go in the previous cell\n",
    "as much as possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Data Loading and Cleaning:**\n",
    "   Describe how you loaded your dataset and the key cleaning steps you implemented (e.g., handling missing data, normalizing formats, or removing duplicates).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Preprocessing and Standardization:**\n",
    "   Summarize your preprocessing pipeline. Include any normalization, tokenization, resizing, or augmentation steps, and explain why each was necessary for your dataset.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Train/Validation/Test Splits:**\n",
    "   Explain how you divided your data into subsets, including the split ratios, random seed, and any stratification or leakage checks you used to verify correctness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Class Distribution and Balance:**\n",
    "   Report your label counts and describe any class imbalances you observed. If applicable, explain how you addressed them (e.g., weighting, oversampling, or data augmentation).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2 – Baseline Model (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Build and train a **simple, fully functional baseline model** to establish a reference level of performance for your dataset.\n",
    "This baseline will help you evaluate whether later architectures and fine-tuning steps actually improve results.\n",
    "\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Construct a baseline model**\n",
    "\n",
    "   * **Images:**\n",
    "     Use a compact CNN, for example\n",
    "     `Conv2D → MaxPooling → Flatten → Dense → Softmax`.\n",
    "   * **Text:**\n",
    "     Use a small embedding-based classifier such as\n",
    "     `Embedding → GlobalAveragePooling → Dense → Softmax`.\n",
    "   * Keep the model small enough to train in minutes on Colab.\n",
    "\n",
    "2. **Compile the model**\n",
    "\n",
    "   * Optimizer: `Adam` or `AdamW`.\n",
    "   * Loss: `categorical_crossentropy` (for multi-class).\n",
    "   * Metrics: at least `accuracy`; add `F1` if appropriate.\n",
    "\n",
    "3. **Train and validate**\n",
    "\n",
    "   * Use **early stopping** on validation loss with the default patience value (e.g., 5 epochs).\n",
    "   * Record number of epochs trained and total runtime.\n",
    "\n",
    "4. **Visualize results**\n",
    "\n",
    "   * Plot **training vs. validation accuracy and loss**.\n",
    "   * Carefully observe: does the model underfit, overfit, or generalize reasonably?\n",
    "\n",
    "5. **Report baseline performance**\n",
    "\n",
    "   * The most important metric is the **validation accuracy at the epoch of minimum validation loss**; this serves as your **benchmark** for all later experiments in this milestone.\n",
    "   * Evaluate on the **test set** and record final metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here; add as many cells as you need but make it clear what the structure is. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "1. **Model Architecture:**\n",
    "   Describe your baseline model and justify why this structure suits your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Training Behavior:**\n",
    "   Summarize the model’s training and validation curves. What trends did you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  3. **Baseline Metrics:**\n",
    "   Report validation and test metrics. What does this performance tell you about dataset difficulty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  4. **Reflection:**\n",
    "   What are the main limitations of your baseline? Which specific improvements (depth, regularization, pretraining) would you try next?\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3 – Custom (Original) Model (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Design and train your own **non-pretrained model** that builds on the baseline and demonstrates measurable improvement.\n",
    "This problem focuses on experimentation: apply one or two clear architectural changes, observe their effects, and evaluate how they influence learning behavior.\n",
    "\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Modify or extend your baseline architecture**\n",
    "\n",
    "   * Begin from your baseline model and introduce one or more meaningful adjustments such as:\n",
    "\n",
    "     * Adding **dropout** or **batch normalization** for regularization.\n",
    "     * Increasing **depth** (extra convolutional or dense layers).\n",
    "     * Using **residual connections** (for CNNs) or **bidirectional LSTMs/GRUs** (for text).\n",
    "     * Trying alternative activations like `ReLU`, `LeakyReLU`, or `GELU`.\n",
    "   * Keep the model small enough to train comfortably on your chosen platform (e.g., Colab)\n",
    "\n",
    "2. **Observe what specific limitations you want to address**\n",
    "\n",
    "   * Identify whether the baseline showed **underfitting**, **overfitting**, or **slow convergence**, and design your modification to target that behavior.\n",
    "   * Make brief notes (in comments or Markdown) describing what you expect the change to influence.\n",
    "\n",
    "3. **Train and evaluate under the same conditions**\n",
    "\n",
    "   * Use the **same data splits**, **random seed**, and **metrics** as in Problem 2.\n",
    "   * Apply **early stopping** on validation loss.\n",
    "   * Track and visualize training/validation accuracy and loss over epochs.\n",
    "\n",
    "4. **Compare outcomes to the baseline**\n",
    "\n",
    "   * Observe differences in convergence speed, stability, and validation/test performance.\n",
    "   * Note whether your modification improved generalization or simply increased model capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "1. **Model Design:**\n",
    "   Describe the architectural changes you introduced compare with your baseline model and what motivated them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Training Results:**\n",
    "   Present key validation and test metrics. Did your modifications improve performance?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Interpretation:**\n",
    "   Discuss what worked, what didn’t, and how your results relate to baseline behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Reflection:**\n",
    "   What insights did this experiment give you about model complexity, regularization, or optimization?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4 – Pretrained Model (Transfer Learning) (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Apply **transfer learning** to see how pretrained knowledge improves accuracy, convergence speed, and generalization.\n",
    "This experiment will help you compare the benefits and trade-offs of using pretrained models versus those trained from scratch.\n",
    "\n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Select a pretrained architecture**\n",
    "\n",
    "   * **Images:** choose from `MobileNetV2`, `ResNet50`, `EfficientNetB0`, or a similar model in `tf.keras.applications`.\n",
    "   * **Text:** choose from `BERT`, `DistilBERT`, `RoBERTa`, or another Transformer available in `transformers`.\n",
    "\n",
    "2. **Adapt the model for your dataset**\n",
    "\n",
    "   * Use the correct **preprocessing function** and **input shape** required by your chosen model.\n",
    "   * Replace the top layer with your own **classification head** (e.g., `Dense(num_classes, activation='softmax')`).\n",
    "\n",
    "3. **Apply transfer learning**\n",
    "\n",
    "   * Choose an appropriate **training strategy** for your pretrained model. Options include:\n",
    "\n",
    "     * **Freezing** the pretrained base and training only a new classification head.\n",
    "     * **Partially fine-tuning** selected upper layers of the base model.\n",
    "     * **Full fine-tuning** (all layers trainable) with a reduced learning rate.\n",
    "   * Adjust your learning rate schedule to match your strategy (e.g., smaller LR for fine-tuning).\n",
    "   * Observe how your chosen approach affects **validation loss**, **training time**, and **model stability**.\n",
    "\n",
    "4. **Train and evaluate under consistent conditions**\n",
    "\n",
    "   * Use the same **splits**, **metrics**, and **evaluation protocol** as in earlier problems.\n",
    "   * Record training duration, validation/test performance, and any resource constraints (GPU memory, runtime).\n",
    "\n",
    "5. **Compare and analyze**\n",
    "\n",
    "   * Observe how transfer learning changes both **performance** and **efficiency** relative to your baseline and custom models.\n",
    "   * Identify whether the pretrained model improved accuracy, sped up convergence, or introduced new challenges.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (5 pts each)\n",
    "\n",
    "1. **Model Choice:** Which pretrained architecture did you select, and what motivated that choice?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Fine-Tuning Plan:** Describe your fine-tuning strategy and why you chose it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Performance:** Report key metrics and compare them with your baseline and custom models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Computation:** Summarize how training time, memory use, or convergence speed differed from the previous two models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5 – Comparative Evaluation and Discussion (20 pts)\n",
    "\n",
    "### Goal\n",
    "\n",
    "Compare your **baseline**, **custom**, and **pretrained** models to evaluate how design choices affected performance, efficiency, and generalization.\n",
    "This problem brings your work together and encourages reflection on what you’ve learned about model behavior and trade-offs.\n",
    "\n",
    "**Note** that this is not your final report, and you will continue to refine your results for the final report. \n",
    "\n",
    "### Steps to Follow\n",
    "\n",
    "1. **Compile key results**\n",
    "\n",
    "   * Gather your main metrics for each model: **accuracy**, **F1**, **training time**, and **parameter count or model size**.\n",
    "   * Ensure all numbers come from the same evaluation protocol and test set.\n",
    "\n",
    "2. **Visualize the comparison**\n",
    "\n",
    "   * Present results in a **single, well-organized chart or table**.\n",
    "   * Optionally, include training curves or confusion matrices for additional insight.\n",
    "\n",
    "3. **Analyze comparative performance**\n",
    "\n",
    "   * Observe which model performed best by your chosen metric(s).\n",
    "   * Note patterns in efficiency (training speed, memory use) and stability (validation variance).\n",
    "\n",
    "4. **Inspect model behavior**\n",
    "\n",
    "   * Look at a few representative misclassifications or difficult examples.\n",
    "   * Identify whether certain classes or inputs consistently caused errors.\n",
    "\n",
    "5. **Plan forward improvements**\n",
    "\n",
    "   * In the final report, you will use your best model and conclude your investigation of your dataset. Based on your observations, decide on a model and next steps for refining your approach in the final project (e.g., regularization, data augmentation, model scaling, or more targeted fine-tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graded Questions (4 pts each)\n",
    "\n",
    "1. **Summary Table and Performance Analysis:** Present a clear quantitative comparison of all three models. Which model achieved the best overall results, and what factors contributed to its success?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Trade-Offs:** Discuss how complexity, accuracy, and efficiency balanced across your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.2. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Error Patterns:** Describe the types of examples or classes that remained challenging for all models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.3. **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Next Steps:** Based on these findings, decide on a model to go forward with and outline your plan for improving that model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.4 **Your answer here:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Question: Describe what use you made of generative AI tools in preparing this Milestone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AI Question: Your answer here:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfmetal",
   "language": "python",
   "name": "tfmetal"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
